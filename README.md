# Manual Propagation for Online Retail Store

## Project Overview
This project involves building a simple neural network manually to optimise a recommendation engine for an online retail store. The focus is on understanding neural network theory, implementing manual forward and backward propagation, and using gradient descent for model optimisation.

## Key Skills and Techniques
- **Neural Network Theory:** Understanding the fundamentals of neural networks through manual implementation.
- **Forward & Backward Propagation:** Detailed hands-on implementation of the forward and backward passes, including manual gradient calculation.
- **Activation Functions:** Applied ReLU and Sigmoid functions and their derivatives for model training and optimisation.
- **Optimisation:** Used gradient descent to update weights and biases, observing the impact on model performance.
- **Visualisation:** Plotted training loss and accuracy over epochs to monitor optimisation.
- **Libraries:** `NumPy`, `matplotlib` for manual computations and visualisations.

## Results & Reflections
- **Solidified Understanding:** The manual implementation of forward and backward propagation deepened understanding of neural network mechanics.
- **Potential Improvements:** Identified areas to explore further, such as adjusting network depth, tuning hyperparameters, and adding visualisation tools to track performance more effectively.

## Usage
Refer to the notebook for the complete code, step-by-step implementation, and insights into neural network theory and optimisation.

## License
This project is licensed under the MIT License. See the `LICENSE` file for more details.
